{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [How to identify the right independent variables for Machine Learning Supervised Algorithms?](https://towardsdatascience.com/how-to-identify-the-right-independent-variables-for-machine-learning-supervised-algorithms-439986562d32)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a very famous acronym GIGO in the field of computer science which I have learnt in my school days. GIGO stands for garbage in and garbages out. Essentially it means that if we feed inappropriate and junk data to computer programs and algorithms, then it will result in junk and incorrect results.\n",
    "Machine learning algorithms are the same as us human beings. Broadly machine learning algorithms have two phases — learning and predicting. \n",
    "\n",
    "Learning environment and parameters should be similar to the condition in which prediction to be done in future. Algorithms trained on an unbiased data sample, and permutations of the input variables values a true reflection of full population dataset are well equipped to make an accurate prediction.\n",
    "\n",
    "One of the cornerstones for the success of the Supervised machine learning algorithms is selecting the right set of the independent variable for the learning phase. In this article, I will discuss a structured approach to select the right independent variables to feed the algorithms. We do not want to overfeed redundant data points i.e. highly related (**Multicollinearity**) data and complicate the model without increasing the prediction accuracy. In fact, sometime overfeeding the data can decrease the prediction accuracy. On the other hand, we need to make sure that the model is not oversimplified and reflects true complexity.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objective"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to build a model to predict the stock price of the company ASML. We have downloaded the stock price data of few of the ASML’s customer, competitors and index points for the last 20 years. We are not sure which of these data points to include to build the ASML stock prediction model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Data File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I have written a small function which I can call from different programs to download the stock price for the last 20 years."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\"\"\"Filename - GetStockData.py is a function to download the stock from 1st Jan 2000 until current date\"\"\"\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def stockdata(ticker):\n",
    "    start= dt.datetime(2000,1,1)    ## Start Date Range\n",
    "    end=dt.datetime.now()    ## Curret date as end date Range\n",
    "    Stock=web.DataReader(ticker, \"yahoo\", start, end)\n",
    "    \n",
    "    name=str(ticker) + \".xlsx\"\n",
    "    Stock.to_excel(name)\n",
    "    return ()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function stockdata() is called from another program with ticker symbols to download the data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ticker= [\"MU\", \"ASML\",\"TSM\",\"QCOM\", \"UMC\", \"^SOX\", \"INTC\",\"^IXIC\"]\n",
    "for i in ticker:\n",
    "    stockdata(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 'path = os.getcwd()\n",
    "# files= os.\n",
    "# files_xls = [f for f in files if f[-3:] == 'xls']\n",
    "# files_xls\n",
    "# \n",
    "# df = pd.DataFrame()\n",
    "# \n",
    "# def excel_to_dataframe(ticker):\n",
    "#     name2=\"data/stock_data/\" + str(ticker) + \".xlsx\"\n",
    "#     df = pd.read_excel(name2).append\n",
    "#     return()\n",
    "# \n",
    "# for j in ticker:\n",
    "#     excel_to_dataframe(j)'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "files = [file for file in os.listdir('./data/stock_data')]\n",
    "stock_data = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_excel(\"./data/stock_data/\"+file)\n",
    "    stock_data=pd.merge(stock_data, df, left_index=True, right_index=True)\n",
    "#all_months_data.to_csv(\"all_data.csv\",index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/r8/zdlnr35s6qz6zx67nmc9bdnm0000gn/T/ipykernel_73135/3544605027.py:5: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Low_x', 'High_x', 'Date_x', 'Close_x', 'Adj Close_x', 'Open_x', 'Volume_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  stock_data=pd.merge(stock_data, df, left_index=True, right_index=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('learn_mach3': conda)"
  },
  "interpreter": {
   "hash": "3f54e69e0805835e9cd1ab82d5123d8a1efb20783328bc60d7bc4235941c29f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}